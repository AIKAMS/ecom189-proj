{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-02T10:33:41.346951Z",
     "start_time": "2025-02-02T10:33:40.960561Z"
    }
   },
   "source": [
    "from entsoe.mappings import DOCUMENTTYPE\n",
    "from torchgen.api.lazy import process_ir_type\n",
    "\n",
    "API_TOKEN = ''\n",
    "\n",
    "from entsoe import EntsoePandasClient\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "client = EntsoePandasClient(api_key=API_TOKEN)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:39:14.205644Z",
     "start_time": "2025-02-01T18:38:18.977596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start = pd.Timestamp('20240101', tz='Europe/London')\n",
    "end = pd.Timestamp('20241231T2359', tz='Europe/London')\n",
    "\n",
    "df = client.query_generation(\n",
    "    country_code='AT',\n",
    "    start=start, end=end ,\n",
    "    DOCUMENTTYPE = 'A71',\n",
    "    nett=True,\n",
    ")"
   ],
   "id": "b56cc1f690d759a4",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[96], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m start \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mTimestamp(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m20240101\u001B[39m\u001B[38;5;124m'\u001B[39m, tz\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEurope/London\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m end \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mTimestamp(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m20241231T2359\u001B[39m\u001B[38;5;124m'\u001B[39m, tz\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEurope/London\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m df \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mquery_generation(\n\u001B[0;32m      5\u001B[0m     country_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAT\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      6\u001B[0m     start\u001B[38;5;241m=\u001B[39mstart, end\u001B[38;5;241m=\u001B[39mend ,\n\u001B[0;32m      7\u001B[0m     DOCUMENTTYPE \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA71\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      8\u001B[0m     nett\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m      9\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\entsoe\\decorators.py:124\u001B[0m, in \u001B[0;36myear_limited.<locals>.year_wrapper\u001B[1;34m(start, end, *args, **kwargs)\u001B[0m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _start, _end \u001B[38;5;129;01min\u001B[39;00m blocks:\n\u001B[0;32m    123\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 124\u001B[0m         frame \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, start\u001B[38;5;241m=\u001B[39m_start, end\u001B[38;5;241m=\u001B[39m_end, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    125\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_query_unavailability\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(frame\u001B[38;5;241m.\u001B[39mindex, pd\u001B[38;5;241m.\u001B[39mDatetimeIndex):\n\u001B[0;32m    126\u001B[0m             \u001B[38;5;66;03m# Due to partial matching func may return data indexed by\u001B[39;00m\n\u001B[0;32m    127\u001B[0m             \u001B[38;5;66;03m# timestamps outside _start and _end. In order to avoid\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    132\u001B[0m             \u001B[38;5;66;03m# If there are repeating records in a single frame (e.g. due\u001B[39;00m\n\u001B[0;32m    133\u001B[0m             \u001B[38;5;66;03m# to corrections) then the result will also have them.\u001B[39;00m\n\u001B[0;32m    134\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m is_first_frame:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\entsoe\\entsoe.py:1436\u001B[0m, in \u001B[0;36mEntsoePandasClient.query_generation\u001B[1;34m(self, country_code, start, end, psr_type, nett, **kwargs)\u001B[0m\n\u001B[0;32m   1420\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1421\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   1422\u001B[0m \u001B[38;5;124;03m----------\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1433\u001B[0m \u001B[38;5;124;03mpd.DataFrame\u001B[39;00m\n\u001B[0;32m   1434\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1435\u001B[0m area \u001B[38;5;241m=\u001B[39m lookup_area(country_code)\n\u001B[1;32m-> 1436\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(EntsoePandasClient, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mquery_generation(\n\u001B[0;32m   1437\u001B[0m     country_code\u001B[38;5;241m=\u001B[39marea, start\u001B[38;5;241m=\u001B[39mstart, end\u001B[38;5;241m=\u001B[39mend, psr_type\u001B[38;5;241m=\u001B[39mpsr_type)\n\u001B[0;32m   1438\u001B[0m df \u001B[38;5;241m=\u001B[39m parse_generation(text, nett\u001B[38;5;241m=\u001B[39mnett)\n\u001B[0;32m   1439\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mtz_convert(area\u001B[38;5;241m.\u001B[39mtz)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\entsoe\\entsoe.py:372\u001B[0m, in \u001B[0;36mEntsoeRawClient.query_generation\u001B[1;34m(self, country_code, start, end, psr_type, **kwargs)\u001B[0m\n\u001B[0;32m    370\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m psr_type:\n\u001B[0;32m    371\u001B[0m     params\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpsrType\u001B[39m\u001B[38;5;124m'\u001B[39m: psr_type})\n\u001B[1;32m--> 372\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_base_request(params\u001B[38;5;241m=\u001B[39mparams, start\u001B[38;5;241m=\u001B[39mstart, end\u001B[38;5;241m=\u001B[39mend)\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\u001B[38;5;241m.\u001B[39mtext\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\entsoe\\decorators.py:24\u001B[0m, in \u001B[0;36mretry.<locals>.retry_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_count):\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 24\u001B[0m         result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (requests\u001B[38;5;241m.\u001B[39mConnectionError, gaierror) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     26\u001B[0m         error \u001B[38;5;241m=\u001B[39m e\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\entsoe\\entsoe.py:97\u001B[0m, in \u001B[0;36mEntsoeRawClient._base_request\u001B[1;34m(self, params, start, end)\u001B[0m\n\u001B[0;32m     94\u001B[0m params\u001B[38;5;241m.\u001B[39mupdate(base_params)\n\u001B[0;32m     96\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPerforming request to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mURL\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with params \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparams\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 97\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession\u001B[38;5;241m.\u001B[39mget(url\u001B[38;5;241m=\u001B[39mURL, params\u001B[38;5;241m=\u001B[39mparams,\n\u001B[0;32m     98\u001B[0m                             proxies\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproxies, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout)\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    100\u001B[0m     response\u001B[38;5;241m.\u001B[39mraise_for_status()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:602\u001B[0m, in \u001B[0;36mSession.get\u001B[1;34m(self, url, **kwargs)\u001B[0m\n\u001B[0;32m    594\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001B[39;00m\n\u001B[0;32m    595\u001B[0m \n\u001B[0;32m    596\u001B[0m \u001B[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m    597\u001B[0m \u001B[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001B[39;00m\n\u001B[0;32m    598\u001B[0m \u001B[38;5;124;03m:rtype: requests.Response\u001B[39;00m\n\u001B[0;32m    599\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    601\u001B[0m kwargs\u001B[38;5;241m.\u001B[39msetdefault(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 602\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGET\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:746\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    743\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    745\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n\u001B[1;32m--> 746\u001B[0m     r\u001B[38;5;241m.\u001B[39mcontent\n\u001B[0;32m    748\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\models.py:902\u001B[0m, in \u001B[0;36mResponse.content\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    900\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    901\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 902\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter_content(CONTENT_CHUNK_SIZE)) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    904\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content_consumed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    905\u001B[0m \u001B[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001B[39;00m\n\u001B[0;32m    906\u001B[0m \u001B[38;5;66;03m# since we exhausted the data.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\models.py:820\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[1;34m()\u001B[0m\n\u001B[0;32m    818\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    819\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 820\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    822\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:1057\u001B[0m, in \u001B[0;36mstream\u001B[1;34m(self, amt, decode_content)\u001B[0m\n\u001B[0;32m   1044\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstream\u001B[39m(\n\u001B[0;32m   1045\u001B[0m     \u001B[38;5;28mself\u001B[39m, amt: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m16\u001B[39m, decode_content: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1046\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m typing\u001B[38;5;241m.\u001B[39mGenerator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[0;32m   1047\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1048\u001B[0m \u001B[38;5;124;03m    A generator wrapper for the read() method. A call will block until\u001B[39;00m\n\u001B[0;32m   1049\u001B[0m \u001B[38;5;124;03m    ``amt`` bytes have been read from the connection or until the\u001B[39;00m\n\u001B[0;32m   1050\u001B[0m \u001B[38;5;124;03m    connection is closed.\u001B[39;00m\n\u001B[0;32m   1051\u001B[0m \n\u001B[0;32m   1052\u001B[0m \u001B[38;5;124;03m    :param amt:\u001B[39;00m\n\u001B[0;32m   1053\u001B[0m \u001B[38;5;124;03m        How much of the content to read. The generator will return up to\u001B[39;00m\n\u001B[0;32m   1054\u001B[0m \u001B[38;5;124;03m        much data per iteration, but may return less. This is particularly\u001B[39;00m\n\u001B[0;32m   1055\u001B[0m \u001B[38;5;124;03m        likely when using compressed data. However, the empty string will\u001B[39;00m\n\u001B[0;32m   1056\u001B[0m \u001B[38;5;124;03m        never be returned.\u001B[39;00m\n\u001B[1;32m-> 1057\u001B[0m \n\u001B[0;32m   1058\u001B[0m \u001B[38;5;124;03m    :param decode_content:\u001B[39;00m\n\u001B[0;32m   1059\u001B[0m \u001B[38;5;124;03m        If True, will attempt to decode the body based on the\u001B[39;00m\n\u001B[0;32m   1060\u001B[0m \u001B[38;5;124;03m        'content-encoding' header.\u001B[39;00m\n\u001B[0;32m   1061\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   1062\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunked \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupports_chunked_reads():\n\u001B[0;32m   1063\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread_chunked(amt, decode_content\u001B[38;5;241m=\u001B[39mdecode_content)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:1209\u001B[0m, in \u001B[0;36mread_chunked\u001B[1;34m(self, amt, decode_content)\u001B[0m\n\u001B[0;32m   1205\u001B[0m     self._original_response.close()\n\u001B[0;32m   1206\u001B[0m     return None\n\u001B[0;32m   1208\u001B[0m # If a response is already read and closed\n\u001B[1;32m-> 1209\u001B[0m # then return immediately.\n\u001B[0;32m   1210\u001B[0m if self._fp.fp is None:  # type: ignore[union-attr]\n\u001B[0;32m   1211\u001B[0m     return None\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:1155\u001B[0m, in \u001B[0;36m_handle_chunk\u001B[1;34m(self, amt)\u001B[0m\n\u001B[0;32m   1153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1154\u001B[0m     chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39m_safe_read(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_left)  \u001B[38;5;66;03m# type: ignore[union-attr]\u001B[39;00m\n\u001B[1;32m-> 1155\u001B[0m     returned_chunk \u001B[38;5;241m=\u001B[39m chunk\n\u001B[0;32m   1156\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39m_safe_read(\u001B[38;5;241m2\u001B[39m)  \u001B[38;5;66;03m# type: ignore[union-attr] # Toss the CRLF at the end of the chunk.\u001B[39;00m\n\u001B[0;32m   1157\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_left \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\http\\client.py:640\u001B[0m, in \u001B[0;36mHTTPResponse._safe_read\u001B[1;34m(self, amt)\u001B[0m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_safe_read\u001B[39m(\u001B[38;5;28mself\u001B[39m, amt):\n\u001B[0;32m    634\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Read the number of bytes requested.\u001B[39;00m\n\u001B[0;32m    635\u001B[0m \n\u001B[0;32m    636\u001B[0m \u001B[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001B[39;00m\n\u001B[0;32m    637\u001B[0m \u001B[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001B[39;00m\n\u001B[0;32m    638\u001B[0m \u001B[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001B[39;00m\n\u001B[0;32m    639\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 640\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mread(amt)\n\u001B[0;32m    641\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m<\u001B[39m amt:\n\u001B[0;32m    642\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m IncompleteRead(data, amt\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(data))\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\socket.py:708\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    706\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    707\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 708\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39mrecv_into(b)\n\u001B[0;32m    709\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    710\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\ssl.py:1252\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1248\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1249\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1250\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1251\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1252\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(nbytes, buffer)\n\u001B[0;32m   1253\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\ssl.py:1104\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1102\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1104\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[0;32m   1105\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1106\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:38:15.726664Z",
     "start_time": "2025-02-01T18:38:15.715845Z"
    }
   },
   "cell_type": "code",
   "source": "df.head(20)",
   "id": "2b7b75315ff77c93",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[95], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m20\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T12:38:05.725559Z",
     "start_time": "2025-01-31T12:38:05.722054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "countries = [\n",
    "    \"10YAT-APG------L\",     # Austria\n",
    "    \"10YBE----------2\",     # Belgium\n",
    "    \"10YBG-ESO-----R\",      # Bulgaria\n",
    "    '10YHR-HEP------M',     # Croatia\n",
    "    '10YCY-1001A0003J',     # Cyprus\n",
    "    \"10YCZ-CEPS-----N\",     # Czech Republic\n",
    "    \"10YDK-1--------W\",     # Denmark\n",
    "    '10Y1001A1001A39I'      # Estonia\n",
    "    \"10YFI-1--------U\",     # Finland\n",
    "    \"10YFR-RTE------C\",     # France\n",
    "    \"10YDE-VE-------2\",     # Germany\n",
    "    \"10YGR-HTSO-----Y\",     # Greece\n",
    "    \"10YHU-MAVIR----U\",     # Hungary\n",
    "    'IS',                   # Iceland\n",
    "    \"10YIE-1001A00010\",     # Ireland\n",
    "    \"10YIT-GRTN-----B\",     # Italy\n",
    "    \"10YLT-1001A0008Q\",     # Lithuania\n",
    "    \"10YLV-1001A00074\",     # Latvia\n",
    "    '10YLU-CEGEDEL-NQ',     # Luxembourg\n",
    "                            # Liechtenstein not available\n",
    "    '10Y1001A1001A93C'      # Malta\n",
    "    \"10YNL----------L\",     # Netherlands\n",
    "    \"10YNO-1--------2\",     # Norway\n",
    "    \"10YPL-AREA-----S\",     # Poland\n",
    "    \"10YPT-REN------W\",     # Portugal\n",
    "    \"10YRO-TEL------P\",     # Romania\n",
    "    \"10YSE-1--------K\",     # Sweden\n",
    "    \"10YSI-ELES-----O\",     # Slovenia\n",
    "    '10YSK-SEPS-----K',     # Slovakia\n",
    "    \"10YES-REE------0\",     # Spain\n",
    "    \"10YCH-SWISSGRIDZ\"      # Switzerland (EFTA)\n",
    "]\n"
   ],
   "id": "1152682254e0a443",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:33:46.779992Z",
     "start_time": "2025-02-02T10:33:46.777337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "countries = [\n",
    "    'AT',\n",
    "    'BE',\n",
    "    'BG',\n",
    "    'HR',\n",
    "    'CY',\n",
    "    'CZ',\n",
    "    'DK',\n",
    "    'EE',\n",
    "    'FI',\n",
    "    'FR',\n",
    "    'DE',\n",
    "    'GR',\n",
    "    'HU',\n",
    "    'IS',\n",
    "    'IT',\n",
    "    'LV',\n",
    "    'LT',\n",
    "    'LU',\n",
    "    'MT',\n",
    "    'UK',\n",
    "    'NL',\n",
    "    'NO',\n",
    "    'PL',\n",
    "    'PT',\n",
    "    'RO',\n",
    "    'SK',\n",
    "    'SI',\n",
    "    'GB_NIR',\n",
    "    'ES',\n",
    "    'SE',\n",
    "    'CH'\n",
    "]"
   ],
   "id": "e8b644702d29cf48",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:33:48.824391Z",
     "start_time": "2025-02-02T10:33:48.820817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "country_timezones = {\n",
    "    'AT': 'Europe/Vienna',\n",
    "    'BE': 'Europe/Brussels',\n",
    "    'BG': 'Europe/Sofia',\n",
    "    'HR': 'Europe/Zagreb',\n",
    "    'CY': 'Asia/Nicosia',\n",
    "    'CZ': 'Europe/Prague',\n",
    "    'DK': 'Europe/Copenhagen',\n",
    "    'EE': 'Europe/Tallinn',\n",
    "    'FI': 'Europe/Helsinki',\n",
    "    'FR': 'Europe/Paris',\n",
    "    'DE': 'Europe/Berlin',\n",
    "    'GR': 'Europe/Athens',\n",
    "    'HU': 'Europe/Budapest',\n",
    "    'IS': 'Atlantic/Reykjavik',\n",
    "    'IT': 'Europe/Rome',\n",
    "    'LV': 'Europe/Riga',\n",
    "    'LT': 'Europe/Vilnius',\n",
    "    'LU': 'Europe/Luxembourg',\n",
    "    'MT': 'Europe/Malta',\n",
    "    'UK': 'Europe/London',\n",
    "    'NL': 'Europe/Amsterdam',\n",
    "    'NO': 'Europe/Oslo',\n",
    "    'PL': 'Europe/Warsaw',\n",
    "    'PT': 'Europe/Lisbon',\n",
    "    'RO': 'Europe/Bucharest',\n",
    "    'SK': 'Europe/Bratislava',\n",
    "    'SI': 'Europe/Ljubljana',\n",
    "    'GB_NIR': 'Europe/Belfast',\n",
    "    'ES': 'Europe/Madrid',\n",
    "    'SE': 'Europe/Stockholm',\n",
    "    'CH': 'Europe/Zurich'\n",
    "}"
   ],
   "id": "28564defabf3189a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T10:33:50.693271Z",
     "start_time": "2025-02-02T10:33:50.690198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "psr_types = {\n",
    "    \"B01\": \"Biomass\",\n",
    "    \"B02\": \"Fossil Brown coal/Lignite\",\n",
    "    \"B03\": \"Fossil Coal-derived gas\",\n",
    "    \"B04\": \"Fossil Gas\",\n",
    "    \"B05\": \"Fossil Hard coal\",\n",
    "    \"B06\": \"Fossil Oil\",\n",
    "    \"B07\": \"Fossil Oil shale\",\n",
    "    \"B08\": \"Fossil Peat\",\n",
    "    \"B09\": \"Geothermal\",\n",
    "    \"B10\": \"Hydro Pumped Storage\",\n",
    "    \"B11\": \"Hydro Run-of-river and poundage\",\n",
    "    \"B12\": \"Hydro Water Reservoir\",\n",
    "    \"B13\": \"Marine\",\n",
    "    \"B14\": \"Nuclear\",\n",
    "    \"B15\": \"Other renewable\",\n",
    "    \"B16\": \"Solar\",\n",
    "    \"B17\": \"Waste\",\n",
    "    \"B18\": \"Wind Offshore\",\n",
    "    \"B19\": \"Wind Onshore\",\n",
    "    \"B20\": \"Other\"\n",
    "}\n"
   ],
   "id": "64e19c5d223428b8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-02T10:35:44.640265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Define time range\n",
    "start_year = 2015\n",
    "end_year = 2025  # This will process years 2015 up to 2024\n",
    "\n",
    "# Folder to store individual country-year CSV files\n",
    "data_dir = \"data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Empty list to store DataFrames for later combination\n",
    "data_list = []\n",
    "\n",
    "# Assuming 'countries' is a list of country codes, for example:\n",
    "# countries = ['AT', 'BE', 'DE', ...]\n",
    "for country in countries:\n",
    "    print(f\"Fetching data for country: {country}\")\n",
    "\n",
    "    # Get the timezone for the current country, defaulting to Europe/Vienna if not found.\n",
    "    tz = country_timezones.get(country, \"Europe/Vienna\")\n",
    "\n",
    "    # Loop over years\n",
    "    for year in range(start_year, end_year):\n",
    "        # Create a filename for this country and year combination.\n",
    "        file_name = os.path.join(data_dir, f\"{country}_{year}.csv\")\n",
    "\n",
    "        # Check if file already exists. If so, load it.\n",
    "        if os.path.exists(file_name):\n",
    "            print(f\"Data for {country} in {year} already exists. Loading from file.\")\n",
    "            try:\n",
    "                # Make sure to parse the timestamp column if it is saved as such.\n",
    "                df = pd.read_csv(file_name, parse_dates=[\"timestamp\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_name}: {e}. Attempting to re-download data.\")\n",
    "                df = None\n",
    "        else:\n",
    "            df = None\n",
    "\n",
    "        # If no valid data was loaded, fetch from the API.\n",
    "        if df is None or df.empty:\n",
    "            try:\n",
    "                # Define the start and end timestamps (for one full year) using the country's timezone.\n",
    "                start = pd.Timestamp(f\"{year}-01-01\", tz=tz)\n",
    "                end = pd.Timestamp(f\"{year}-12-31 23:59\", tz=tz)\n",
    "\n",
    "                print(f\"Fetching generation data for {country} in period starting {year} using timezone {tz}...\")\n",
    "                # Replace client.query_generation with your actual API call.\n",
    "                df = client.query_generation(\n",
    "                    country_code=country,\n",
    "                    start=start,\n",
    "                    end=end,\n",
    "                    psr_type=None,\n",
    "                    nett=True\n",
    "                )\n",
    "\n",
    "                # If data exists, format and store it.\n",
    "                if df is not None and not df.empty:\n",
    "                    df[\"country\"] = country\n",
    "                    df[\"year\"] = year\n",
    "\n",
    "                    # Aggregate the data into daily totals (summing up the generation_MW values).\n",
    "                    df = df.resample('D').sum()\n",
    "\n",
    "                    # Save the aggregated DataFrame to CSV for later use.\n",
    "                    df.to_csv(file_name, index=True, index_label=\"timestamp\")\n",
    "                    print(f\"Saved daily aggregated data for {country} in {year} to {file_name}\")\n",
    "                else:\n",
    "                    print(f\"No data found for {country} in {year}.\")\n",
    "                    continue\n",
    "\n",
    "                # Pause to respect API rate limits.\n",
    "                time.sleep(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for {country} in {year}: {e}\")\n",
    "                time.sleep(5)  # Pause in case of an error, then continue to the next iteration.\n",
    "                continue\n",
    "\n",
    "        # Append the daily aggregated DataFrame (from file or API) to the list for later combination.\n",
    "        data_list.append(df)\n",
    "\n",
    "# Combine all individual DataFrames into one final DataFrame if any data was retrieved.\n",
    "if data_list:\n",
    "    final_df = pd.concat(data_list, ignore_index=False)\n",
    "    final_csv_file = \"entsoe_daily_generation_2015_2025.csv\"\n",
    "    final_df.to_csv(final_csv_file, index=True)\n",
    "    print(f\"Data fetching complete! Combined daily aggregated data saved as '{final_csv_file}'\")\n",
    "else:\n",
    "    print(\"No data was retrieved.\")"
   ],
   "id": "8e6a9b6577a4b5ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for country: AT\n",
      "Data for AT in 2015 already exists. Loading from file.\n",
      "Data for AT in 2016 already exists. Loading from file.\n",
      "Data for AT in 2017 already exists. Loading from file.\n",
      "Data for AT in 2018 already exists. Loading from file.\n",
      "Data for AT in 2019 already exists. Loading from file.\n",
      "Data for AT in 2020 already exists. Loading from file.\n",
      "Data for AT in 2021 already exists. Loading from file.\n",
      "Data for AT in 2022 already exists. Loading from file.\n",
      "Data for AT in 2023 already exists. Loading from file.\n",
      "Data for AT in 2024 already exists. Loading from file.\n",
      "Fetching data for country: BE\n",
      "Data for BE in 2015 already exists. Loading from file.\n",
      "Data for BE in 2016 already exists. Loading from file.\n",
      "Data for BE in 2017 already exists. Loading from file.\n",
      "Data for BE in 2018 already exists. Loading from file.\n",
      "Data for BE in 2019 already exists. Loading from file.\n",
      "Data for BE in 2020 already exists. Loading from file.\n",
      "Data for BE in 2021 already exists. Loading from file.\n",
      "Data for BE in 2022 already exists. Loading from file.\n",
      "Data for BE in 2023 already exists. Loading from file.\n",
      "Data for BE in 2024 already exists. Loading from file.\n",
      "Fetching data for country: BG\n",
      "Data for BG in 2015 already exists. Loading from file.\n",
      "Data for BG in 2016 already exists. Loading from file.\n",
      "Data for BG in 2017 already exists. Loading from file.\n",
      "Data for BG in 2018 already exists. Loading from file.\n",
      "Data for BG in 2019 already exists. Loading from file.\n",
      "Data for BG in 2020 already exists. Loading from file.\n",
      "Data for BG in 2021 already exists. Loading from file.\n",
      "Data for BG in 2022 already exists. Loading from file.\n",
      "Data for BG in 2023 already exists. Loading from file.\n",
      "Data for BG in 2024 already exists. Loading from file.\n",
      "Fetching data for country: HR\n",
      "Fetching generation data for HR in period starting 2015 using timezone Europe/Zagreb...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:04:33.246825Z",
     "start_time": "2025-01-31T14:33:48.861943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set time range\n",
    "start_year = 2015\n",
    "end_year = 2025\n",
    "\n",
    "# Empty list to store results\n",
    "data_list = []\n",
    "\n",
    "# Loop over countries\n",
    "for country in countries:\n",
    "    print(f\"Fetching data for country: {country}\")\n",
    "\n",
    "    # Loop over years\n",
    "    for year in range(start_year, end_year, 1):\n",
    "        start = pd.Timestamp(f\"{year}-01-01\", tz=\"UTC\")\n",
    "        end = pd.Timestamp(f\"{year+4}-12-31 23:59\", tz=\"UTC\")\n",
    "\n",
    "        try:\n",
    "            print(f\"Fetching all generation data for {country} in {year}...\")\n",
    "            df = client.query_generation(\n",
    "                country_code=country,\n",
    "                start=start,\n",
    "                end=end,\n",
    "                psr_type=None,\n",
    "                marketAgreementType=\"A01\",  # Retrieve daily data directly\n",
    "                nett=True\n",
    "            )\n",
    "\n",
    "            # If data exists, format and store it\n",
    "            if df is not None and not df.empty:\n",
    "                df.columns = [\"generation_MW\"]  # Ensure correct column name\n",
    "                df[\"country\"] = country\n",
    "                df[\"year\"] = year\n",
    "                data_list.append(df)\n",
    "\n",
    "            time.sleep(1)  # Avoid API rate limits\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {country} in {year}: {e}\")\n",
    "            time.sleep(5)  # Pause in case of error\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "if data_list:\n",
    "    final_df = pd.concat(data_list).reset_index()\n",
    "    final_df.rename(columns={\"index\": \"date\"}, inplace=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    final_df.to_csv(\"entsoe_daily_generation_2015_2025.csv\", index=False)\n",
    "    print(\"Data fetching complete! Saved as 'entsoe_daily_generation_2015_2025.csv'\")\n",
    "else:\n",
    "    print(\"No data was retrieved.\")\n"
   ],
   "id": "57d2222d4503651b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for country: 10YAT-APG------L\n",
      "Fetching all generation data for 10YAT-APG------L in 2015...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YAT-APG------L in 2015: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YAT-APG------L&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=201601010000&periodEnd=201701010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching all generation data for 10YAT-APG------L in 2020...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YAT-APG------L in 2020: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YAT-APG------L&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=202201010000&periodEnd=202301010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for country: 10YBE----------2\n",
      "Fetching all generation data for 10YBE----------2 in 2015...\n",
      "Error fetching data for 10YBE----------2 in 2015: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YBE----------2&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=201501010000&periodEnd=201601010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching all generation data for 10YBE----------2 in 2020...\n",
      "Error fetching data for 10YBE----------2 in 2020: Length mismatch: Expected axis has 11 elements, new values have 1 elements\n",
      "Fetching data for country: 10YBG-ESO-----R\n",
      "Fetching all generation data for 10YBG-ESO-----R in 2015...\n",
      "Error fetching data for 10YBG-ESO-----R in 2015: Invalid country code.\n",
      "Fetching all generation data for 10YBG-ESO-----R in 2020...\n",
      "Error fetching data for 10YBG-ESO-----R in 2020: Invalid country code.\n",
      "Fetching data for country: 10YHR-HEP------M\n",
      "Fetching all generation data for 10YHR-HEP------M in 2015...\n",
      "Error fetching data for 10YHR-HEP------M in 2015: Length mismatch: Expected axis has 12 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YHR-HEP------M in 2020...\n",
      "Error fetching data for 10YHR-HEP------M in 2020: Length mismatch: Expected axis has 12 elements, new values have 1 elements\n",
      "Fetching data for country: 10YCY-1001A0003J\n",
      "Fetching all generation data for 10YCY-1001A0003J in 2015...\n",
      "Error fetching data for 10YCY-1001A0003J in 2015: Length mismatch: Expected axis has 2 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YCY-1001A0003J in 2020...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YCY-1001A0003J in 2020: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YCY-1001A0003J&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=202201010000&periodEnd=202301010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching data for country: 10YCZ-CEPS-----N\n",
      "Fetching all generation data for 10YCZ-CEPS-----N in 2015...\n",
      "Error fetching data for 10YCZ-CEPS-----N in 2015: Length mismatch: Expected axis has 15 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YCZ-CEPS-----N in 2020...\n",
      "Error fetching data for 10YCZ-CEPS-----N in 2020: Length mismatch: Expected axis has 15 elements, new values have 1 elements\n",
      "Fetching data for country: 10YDK-1--------W\n",
      "Fetching all generation data for 10YDK-1--------W in 2015...\n",
      "Error fetching data for 10YDK-1--------W in 2015: Length mismatch: Expected axis has 11 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YDK-1--------W in 2020...\n",
      "Error fetching data for 10YDK-1--------W in 2020: Length mismatch: Expected axis has 10 elements, new values have 1 elements\n",
      "Fetching data for country: 10Y1001A1001A39I10YFI-1--------U\n",
      "Fetching all generation data for 10Y1001A1001A39I10YFI-1--------U in 2015...\n",
      "Error fetching data for 10Y1001A1001A39I10YFI-1--------U in 2015: Invalid country code.\n",
      "Fetching all generation data for 10Y1001A1001A39I10YFI-1--------U in 2020...\n",
      "Error fetching data for 10Y1001A1001A39I10YFI-1--------U in 2020: Invalid country code.\n",
      "Fetching data for country: 10YFR-RTE------C\n",
      "Fetching all generation data for 10YFR-RTE------C in 2015...\n",
      "Error fetching data for 10YFR-RTE------C in 2015: Length mismatch: Expected axis has 11 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YFR-RTE------C in 2020...\n",
      "Error fetching data for 10YFR-RTE------C in 2020: Length mismatch: Expected axis has 12 elements, new values have 1 elements\n",
      "Fetching data for country: 10YDE-VE-------2\n",
      "Fetching all generation data for 10YDE-VE-------2 in 2015...\n",
      "Error fetching data for 10YDE-VE-------2 in 2015: Length mismatch: Expected axis has 14 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YDE-VE-------2 in 2020...\n",
      "Error fetching data for 10YDE-VE-------2 in 2020: Length mismatch: Expected axis has 14 elements, new values have 1 elements\n",
      "Fetching data for country: 10YGR-HTSO-----Y\n",
      "Fetching all generation data for 10YGR-HTSO-----Y in 2015...\n",
      "Error fetching data for 10YGR-HTSO-----Y in 2015: Length mismatch: Expected axis has 7 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YGR-HTSO-----Y in 2020...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YGR-HTSO-----Y in 2020: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YGR-HTSO-----Y&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=202301010000&periodEnd=202401010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching data for country: 10YHU-MAVIR----U\n",
      "Fetching all generation data for 10YHU-MAVIR----U in 2015...\n",
      "Error fetching data for 10YHU-MAVIR----U in 2015: Length mismatch: Expected axis has 12 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YHU-MAVIR----U in 2020...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YHU-MAVIR----U in 2020: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YHU-MAVIR----U&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=202301010000&periodEnd=202401010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching data for country: IS\n",
      "Fetching all generation data for IS in 2015...\n",
      "Error fetching data for IS in 2015: 400 Client Error: Bad Request for url: https://web-api.tp.entsoe.eu/api?documentType=A75&processType=A16&in_Domain=IS&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=201501010000&periodEnd=201601010000\n",
      "Fetching all generation data for IS in 2020...\n",
      "Error fetching data for IS in 2020: 400 Client Error: Bad Request for url: https://web-api.tp.entsoe.eu/api?documentType=A75&processType=A16&in_Domain=IS&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=202001010000&periodEnd=202101010000\n",
      "Fetching data for country: 10YIE-1001A00010\n",
      "Fetching all generation data for 10YIE-1001A00010 in 2015...\n",
      "Error fetching data for 10YIE-1001A00010 in 2015: Length mismatch: Expected axis has 8 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YIE-1001A00010 in 2020...\n",
      "Error fetching data for 10YIE-1001A00010 in 2020: Length mismatch: Expected axis has 8 elements, new values have 1 elements\n",
      "Fetching data for country: 10YIT-GRTN-----B\n",
      "Fetching all generation data for 10YIT-GRTN-----B in 2015...\n",
      "Error fetching data for 10YIT-GRTN-----B in 2015: Length mismatch: Expected axis has 13 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YIT-GRTN-----B in 2020...\n",
      "Error fetching data for 10YIT-GRTN-----B in 2020: Length mismatch: Expected axis has 14 elements, new values have 1 elements\n",
      "Fetching data for country: 10YLT-1001A0008Q\n",
      "Fetching all generation data for 10YLT-1001A0008Q in 2015...\n",
      "Error fetching data for 10YLT-1001A0008Q in 2015: Length mismatch: Expected axis has 9 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YLT-1001A0008Q in 2020...\n",
      "Error fetching data for 10YLT-1001A0008Q in 2020: Length mismatch: Expected axis has 8 elements, new values have 1 elements\n",
      "Fetching data for country: 10YLV-1001A00074\n",
      "Fetching all generation data for 10YLV-1001A00074 in 2015...\n",
      "Error fetching data for 10YLV-1001A00074 in 2015: Length mismatch: Expected axis has 6 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YLV-1001A00074 in 2020...\n",
      "Error fetching data for 10YLV-1001A00074 in 2020: Length mismatch: Expected axis has 6 elements, new values have 1 elements\n",
      "Fetching data for country: 10YLU-CEGEDEL-NQ\n",
      "Fetching all generation data for 10YLU-CEGEDEL-NQ in 2015...\n",
      "Error fetching data for 10YLU-CEGEDEL-NQ in 2015: Length mismatch: Expected axis has 7 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YLU-CEGEDEL-NQ in 2020...\n",
      "Error fetching data for 10YLU-CEGEDEL-NQ in 2020: Length mismatch: Expected axis has 7 elements, new values have 1 elements\n",
      "Fetching data for country: 10Y1001A1001A93C10YNL----------L\n",
      "Fetching all generation data for 10Y1001A1001A93C10YNL----------L in 2015...\n",
      "Error fetching data for 10Y1001A1001A93C10YNL----------L in 2015: Invalid country code.\n",
      "Fetching all generation data for 10Y1001A1001A93C10YNL----------L in 2020...\n",
      "Error fetching data for 10Y1001A1001A93C10YNL----------L in 2020: Invalid country code.\n",
      "Fetching data for country: 10YNO-1--------2\n",
      "Fetching all generation data for 10YNO-1--------2 in 2015...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YNO-1--------2 in 2015: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YNO-1--------2&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=201901010000&periodEnd=202001010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching all generation data for 10YNO-1--------2 in 2020...\n",
      "Error fetching data for 10YNO-1--------2 in 2020: Length mismatch: Expected axis has 8 elements, new values have 1 elements\n",
      "Fetching data for country: 10YPL-AREA-----S\n",
      "Fetching all generation data for 10YPL-AREA-----S in 2015...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YPL-AREA-----S in 2015: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YPL-AREA-----S&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=201801010000&periodEnd=201901010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching all generation data for 10YPL-AREA-----S in 2020...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YPL-AREA-----S in 2020: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YPL-AREA-----S&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=202301010000&periodEnd=202401010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching data for country: 10YPT-REN------W\n",
      "Fetching all generation data for 10YPT-REN------W in 2015...\n",
      "Error fetching data for 10YPT-REN------W in 2015: Length mismatch: Expected axis has 9 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YPT-REN------W in 2020...\n",
      "Error fetching data for 10YPT-REN------W in 2020: Length mismatch: Expected axis has 10 elements, new values have 1 elements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for country: 10YRO-TEL------P\n",
      "Fetching all generation data for 10YRO-TEL------P in 2015...\n",
      "Error fetching data for 10YRO-TEL------P in 2015: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YRO-TEL------P&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=201501010000&periodEnd=201601010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching all generation data for 10YRO-TEL------P in 2020...\n",
      "Error fetching data for 10YRO-TEL------P in 2020: Length mismatch: Expected axis has 9 elements, new values have 1 elements\n",
      "Fetching data for country: 10YSE-1--------K\n",
      "Fetching all generation data for 10YSE-1--------K in 2015...\n",
      "Error fetching data for 10YSE-1--------K in 2015: Length mismatch: Expected axis has 4 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YSE-1--------K in 2020...\n",
      "Error fetching data for 10YSE-1--------K in 2020: Length mismatch: Expected axis has 7 elements, new values have 1 elements\n",
      "Fetching data for country: 10YSI-ELES-----O\n",
      "Fetching all generation data for 10YSI-ELES-----O in 2015...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YSI-ELES-----O in 2015: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YSI-ELES-----O&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=201601010000&periodEnd=201701010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching all generation data for 10YSI-ELES-----O in 2020...\n",
      "Error fetching data for 10YSI-ELES-----O in 2020: Length mismatch: Expected axis has 10 elements, new values have 1 elements\n",
      "Fetching data for country: 10YSK-SEPS-----K\n",
      "Fetching all generation data for 10YSK-SEPS-----K in 2015...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YSK-SEPS-----K in 2015: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YSK-SEPS-----K&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=201901010000&periodEnd=202001010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching all generation data for 10YSK-SEPS-----K in 2020...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YSK-SEPS-----K in 2020: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YSK-SEPS-----K&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=202401010000&periodEnd=202501010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching data for country: 10YES-REE------0\n",
      "Fetching all generation data for 10YES-REE------0 in 2015...\n",
      "Error fetching data for 10YES-REE------0 in 2015: Length mismatch: Expected axis has 20 elements, new values have 1 elements\n",
      "Fetching all generation data for 10YES-REE------0 in 2020...\n",
      "Error fetching data for 10YES-REE------0 in 2020: Length mismatch: Expected axis has 20 elements, new values have 1 elements\n",
      "Fetching data for country: 10YCH-SWISSGRIDZ\n",
      "Fetching all generation data for 10YCH-SWISSGRIDZ in 2015...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YCH-SWISSGRIDZ in 2015: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YCH-SWISSGRIDZ&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=201601010000&periodEnd=201701010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "Fetching all generation data for 10YCH-SWISSGRIDZ in 2020...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for 10YCH-SWISSGRIDZ in 2020: HTTPSConnectionPool(host='web-api.tp.entsoe.eu', port=443): Max retries exceeded with url: /api?documentType=A75&processType=A16&in_Domain=10YCH-SWISSGRIDZ&securityToken=8112075a-2008-46a9-a0b7-d8e7f97e8a47&periodStart=202401010000&periodEnd=202501010000 (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "No data was retrieved.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:16:53.621467Z",
     "start_time": "2025-02-01T18:14:59.756767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import urllib3\n",
    "import re\n",
    "\n",
    "# Disable warnings for unverified HTTPS requests (for testing purposes only)\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    \"\"\"\n",
    "    Parse a duration string like 'PT60M' or 'PT1H' and return a timedelta.\n",
    "    \"\"\"\n",
    "    match = re.match(r'PT(\\d+)([HM])', duration_str)\n",
    "    if match:\n",
    "        value = int(match.group(1))\n",
    "        unit = match.group(2)\n",
    "        if unit == 'H':\n",
    "            return datetime.timedelta(hours=value)\n",
    "        elif unit == 'M':\n",
    "            return datetime.timedelta(minutes=value)\n",
    "    return None\n",
    "\n",
    "# Define the list of years and country codes to query.\n",
    "# (Ensure these values match data available from the API.)\n",
    "years = [2023, 2024]  # Example: note that your sample XML has data for 2023.\n",
    "countries = ['10YCZ-CEPS-----N']\n",
    "\n",
    "# Your security token (if required; otherwise, leave it empty)\n",
    "security_token = API_TOKEN  # Replace with your actual token\n",
    "\n",
    "# Base API URL (without query parameters)\n",
    "base_url = \"https://web-api.tp.entsoe.eu//api\"\n",
    "\n",
    "# Optional: custom headers to mimic a browser\n",
    "headers = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/90.0.4430.93 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# List to store DataFrames for each API call\n",
    "dataframes = []\n",
    "\n",
    "for country in countries:\n",
    "    for year in years:\n",
    "        # Build periodStart and periodEnd for the request.\n",
    "        # Format: YYYYMMDDhhmm (e.g., \"202401010000\" for Jan 1, 2024 00:00)\n",
    "        periodStart = f\"{year}01010000\"\n",
    "        periodEnd = f\"{year}12312300\"\n",
    "\n",
    "        params = {\n",
    "            \"securityToken\": security_token,\n",
    "            \"documentType\": \"A75\",\n",
    "            \"processType\": \"A16\",\n",
    "            \"in_Domain\": country,\n",
    "            \"periodStart\": periodStart,\n",
    "            \"periodEnd\": periodEnd\n",
    "        }\n",
    "\n",
    "        print(f\"Requesting data for {country} in {year}...\")\n",
    "        try:\n",
    "            response = requests.get(base_url, params=params, headers=headers, verify=False)\n",
    "            response.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error retrieving data for {country} in {year}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            root = ET.fromstring(response.content)\n",
    "        except ET.ParseError as e:\n",
    "            print(f\"Error parsing XML for {country} in {year}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Handle the default namespace.\n",
    "        ns = {}\n",
    "        if root.tag.startswith(\"{\"):\n",
    "            ns_uri = root.tag.split(\"}\")[0].strip(\"{\")\n",
    "            ns['ns'] = ns_uri\n",
    "        else:\n",
    "            ns['ns'] = ''\n",
    "\n",
    "        records = []\n",
    "        # Find all TimeSeries elements (using the namespace).\n",
    "        timeseries_elements = root.findall('.//ns:TimeSeries', ns)\n",
    "        if not timeseries_elements:\n",
    "            print(\"No TimeSeries elements found in the XML.\")\n",
    "\n",
    "        for ts in timeseries_elements:\n",
    "            # Locate the Period element (direct child of TimeSeries).\n",
    "            period_elem = ts.find('ns:Period', ns)\n",
    "            if period_elem is None:\n",
    "                continue\n",
    "\n",
    "            # Get the timeInterval inside Period and extract the start and end.\n",
    "            time_interval = period_elem.find('ns:timeInterval', ns)\n",
    "            if time_interval is None:\n",
    "                continue\n",
    "            start_elem = time_interval.find('ns:start', ns)\n",
    "            end_elem = time_interval.find('ns:end', ns)\n",
    "            if start_elem is None or end_elem is None:\n",
    "                continue\n",
    "            try:\n",
    "                # Use the XML-provided start time as the baseline timestamp.\n",
    "                period_start_dt = datetime.datetime.fromisoformat(start_elem.text.replace(\"Z\", \"+00:00\"))\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing period start time '{start_elem.text}': {e}\")\n",
    "                continue\n",
    "\n",
    "            # Resolution is a direct child of Period.\n",
    "            resolution_elem = period_elem.find('ns:resolution', ns)\n",
    "            resolution_str = resolution_elem.text if resolution_elem is not None else None\n",
    "            interval_td = parse_duration(resolution_str) if resolution_str else None\n",
    "\n",
    "            # Find all Point elements directly under Period.\n",
    "            points = period_elem.findall('ns:Point', ns)\n",
    "            for point in points:\n",
    "                pos_elem = point.find('ns:position', ns)\n",
    "                quantity_elem = point.find('ns:quantity', ns)\n",
    "                if pos_elem is None or quantity_elem is None:\n",
    "                    continue\n",
    "                try:\n",
    "                    pos = int(pos_elem.text)\n",
    "                    quantity = float(quantity_elem.text)\n",
    "                except Exception as e:\n",
    "                    print(\"Error parsing position or quantity:\", e)\n",
    "                    continue\n",
    "\n",
    "                # Calculate the timestamp for this point.\n",
    "                timestamp = period_start_dt + (interval_td * (pos - 1)) if interval_td else period_start_dt\n",
    "                record = {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"quantity\": quantity,\n",
    "                    \"resolution\": resolution_str,\n",
    "                    \"in_Domain\": country,\n",
    "                    \"year\": year,\n",
    "                    \"period_start\": start_elem.text,\n",
    "                    \"period_end\": end_elem.text\n",
    "                }\n",
    "                records.append(record)\n",
    "\n",
    "        if records:\n",
    "            df_temp = pd.DataFrame(records)\n",
    "            dataframes.append(df_temp)\n",
    "        else:\n",
    "            print(f\"No valid records found for {country} in {year}.\")\n",
    "\n",
    "        # Pause briefly to respect API rate limits.\n",
    "        time.sleep(0.5)\n",
    "\n",
    "if dataframes:\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(\"Combined DataFrame:\")\n",
    "    print(combined_df.head())\n",
    "else:\n",
    "    print(\"No data was retrieved from the API.\")\n"
   ],
   "id": "79f6f9556d462eb9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting data for 10YCZ-CEPS-----N in 2023...\n",
      "Requesting data for 10YCZ-CEPS-----N in 2024...\n",
      "Combined DataFrame:\n",
      "                  timestamp  quantity resolution         in_Domain  year  \\\n",
      "0 2023-01-01 00:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
      "1 2023-01-01 01:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
      "2 2023-01-01 02:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
      "3 2023-01-01 03:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
      "4 2023-01-01 04:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
      "\n",
      "        period_start         period_end  \n",
      "0  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
      "1  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
      "2  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
      "3  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
      "4  2023-01-01T00:00Z  2023-12-31T23:00Z  \n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:17:09.935401Z",
     "start_time": "2025-02-01T18:17:09.925983Z"
    }
   },
   "cell_type": "code",
   "source": "combined_df.head(48)",
   "id": "96366a4b8d8dac44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   timestamp  quantity resolution         in_Domain  year  \\\n",
       "0  2023-01-01 00:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "1  2023-01-01 01:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "2  2023-01-01 02:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "3  2023-01-01 03:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "4  2023-01-01 04:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "5  2023-01-01 05:00:00+00:00     267.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "6  2023-01-01 06:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "7  2023-01-01 07:00:00+00:00     267.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "8  2023-01-01 08:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "9  2023-01-01 09:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "10 2023-01-01 10:00:00+00:00     267.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "11 2023-01-01 11:00:00+00:00     267.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "12 2023-01-01 12:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "13 2023-01-01 13:00:00+00:00     262.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "14 2023-01-01 14:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "15 2023-01-01 15:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "16 2023-01-01 16:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "17 2023-01-01 17:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "18 2023-01-01 18:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "19 2023-01-01 19:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "20 2023-01-01 20:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "21 2023-01-01 21:00:00+00:00     267.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "22 2023-01-01 22:00:00+00:00     263.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "23 2023-01-01 23:00:00+00:00     261.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "24 2023-01-02 00:00:00+00:00     262.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "25 2023-01-02 01:00:00+00:00     262.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "26 2023-01-02 02:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "27 2023-01-02 03:00:00+00:00     267.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "28 2023-01-02 04:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "29 2023-01-02 05:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "30 2023-01-02 06:00:00+00:00     276.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "31 2023-01-02 07:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "32 2023-01-02 08:00:00+00:00     265.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "33 2023-01-02 09:00:00+00:00     264.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "34 2023-01-02 10:00:00+00:00     263.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "35 2023-01-02 11:00:00+00:00     264.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "36 2023-01-02 12:00:00+00:00     267.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "37 2023-01-02 13:00:00+00:00     266.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "38 2023-01-02 14:00:00+00:00     264.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "39 2023-01-02 15:00:00+00:00     263.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "40 2023-01-02 16:00:00+00:00     269.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "41 2023-01-02 17:00:00+00:00     269.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "42 2023-01-02 18:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "43 2023-01-02 19:00:00+00:00     264.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "44 2023-01-02 20:00:00+00:00     270.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "45 2023-01-02 21:00:00+00:00     269.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "46 2023-01-02 22:00:00+00:00     268.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "47 2023-01-02 23:00:00+00:00     265.0      PT60M  10YCZ-CEPS-----N  2023   \n",
       "\n",
       "         period_start         period_end  \n",
       "0   2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "1   2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "2   2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "3   2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "4   2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "5   2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "6   2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "7   2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "8   2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "9   2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "10  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "11  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "12  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "13  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "14  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "15  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "16  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "17  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "18  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "19  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "20  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "21  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "22  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "23  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "24  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "25  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "26  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "27  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "28  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "29  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "30  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "31  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "32  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "33  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "34  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "35  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "36  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "37  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "38  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "39  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "40  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "41  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "42  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "43  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "44  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "45  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "46  2023-01-01T00:00Z  2023-12-31T23:00Z  \n",
       "47  2023-01-01T00:00Z  2023-12-31T23:00Z  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>quantity</th>\n",
       "      <th>resolution</th>\n",
       "      <th>in_Domain</th>\n",
       "      <th>year</th>\n",
       "      <th>period_start</th>\n",
       "      <th>period_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00+00:00</td>\n",
       "      <td>266.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00+00:00</td>\n",
       "      <td>266.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00+00:00</td>\n",
       "      <td>266.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00+00:00</td>\n",
       "      <td>266.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00+00:00</td>\n",
       "      <td>266.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-01 05:00:00+00:00</td>\n",
       "      <td>267.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-01 06:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-01 07:00:00+00:00</td>\n",
       "      <td>267.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-01 08:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-01 09:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-01 10:00:00+00:00</td>\n",
       "      <td>267.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-01-01 11:00:00+00:00</td>\n",
       "      <td>267.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-01-01 12:00:00+00:00</td>\n",
       "      <td>266.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-01-01 13:00:00+00:00</td>\n",
       "      <td>262.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-01-01 14:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-01-01 15:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-01-01 16:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-01-01 17:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-01-01 18:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-01-01 19:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-01-01 20:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-01-01 21:00:00+00:00</td>\n",
       "      <td>267.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-01-01 22:00:00+00:00</td>\n",
       "      <td>263.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-01-01 23:00:00+00:00</td>\n",
       "      <td>261.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-01-02 00:00:00+00:00</td>\n",
       "      <td>262.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-01-02 01:00:00+00:00</td>\n",
       "      <td>262.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-01-02 02:00:00+00:00</td>\n",
       "      <td>266.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-01-02 03:00:00+00:00</td>\n",
       "      <td>267.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-01-02 04:00:00+00:00</td>\n",
       "      <td>266.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-01-02 05:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-01-02 06:00:00+00:00</td>\n",
       "      <td>276.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-01-02 07:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-01-02 08:00:00+00:00</td>\n",
       "      <td>265.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-01-02 09:00:00+00:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023-01-02 10:00:00+00:00</td>\n",
       "      <td>263.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023-01-02 11:00:00+00:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2023-01-02 12:00:00+00:00</td>\n",
       "      <td>267.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023-01-02 13:00:00+00:00</td>\n",
       "      <td>266.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023-01-02 14:00:00+00:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2023-01-02 15:00:00+00:00</td>\n",
       "      <td>263.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2023-01-02 16:00:00+00:00</td>\n",
       "      <td>269.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2023-01-02 17:00:00+00:00</td>\n",
       "      <td>269.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2023-01-02 18:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2023-01-02 19:00:00+00:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2023-01-02 20:00:00+00:00</td>\n",
       "      <td>270.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2023-01-02 21:00:00+00:00</td>\n",
       "      <td>269.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2023-01-02 22:00:00+00:00</td>\n",
       "      <td>268.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2023-01-02 23:00:00+00:00</td>\n",
       "      <td>265.0</td>\n",
       "      <td>PT60M</td>\n",
       "      <td>10YCZ-CEPS-----N</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01T00:00Z</td>\n",
       "      <td>2023-12-31T23:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
